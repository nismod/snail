{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation and infrastructure exposure to flooding\n",
    "\n",
    "This notebook forms the basis of \"Hands-On 5\" in the CCG course.\n",
    "\n",
    "1. Extract infrastructure data from OpenStreetMap\n",
    "2. Extract flood hazard data from Aqueduct\n",
    "3. Intersect floods with roads to calculate exposure\n",
    "4. Open QGIS to look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 1: Extract infrastructure data\n",
    "\n",
    "### Step 1) On your desktop, create a folder called `ghana_tutorial`\n",
    "\n",
    "### Step 2) Create a variable to store the folder location\n",
    "\n",
    "In the cell below, type in the path to your desktop, by changing NAME to match your username as shown on your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit this if using a Mac (otherwise delete)\n",
    "data_folder = \"/Users/NAME/Desktop/ghana_tutorial\"\n",
    "\n",
    "# edit this if using Windows (otherwise delete)\n",
    "data_folder = \"C:\\\\Users\\\\NAME\\\\Desktop\\\\ghana_tutorial\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3) Load Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The os and subprocess modules are built into Python\n",
    "# see https://docs.python.org/3/library/os.html\n",
    "import os \n",
    "# see https://docs.python.org/3/library/subprocess.html\n",
    "import subprocess \n",
    "\n",
    "# Pandas and GeoPandas are libraries for working with datasets\n",
    "# see https://geopandas.org/\n",
    "import geopandas as gpd\n",
    "# see https://pandas.pydata.org/\n",
    "import pandas as pd \n",
    "\n",
    "# PyPROJ is a library for working with geographic projections \n",
    "# see https://pyproj4.github.io/\n",
    "from pyproj import Geod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4) and 5) Download and save data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the `ghana-latest-free.shp.zip` dataset from http://download.geofabrik.de/africa/ghana.html, extract the zip folder and save the extracted folder within your new folder `ghana_tutorial`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6) Load the road dataset you've just downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GHA_OSM_roads = gpd.read_file(\n",
    "    os.path.join(data_folder, 'ghana-latest-free.shp', 'gis_osm_roads_free_1.shp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7) To take a look at the data and the attribute table fill in and run the next two cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GHA_OSM_roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GHA_OSM_roads.fclass.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8) Next we want to make a couple of changes to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the specified columns\n",
    "GHA_OSM_roads = GHA_OSM_roads[['osm_id', 'fclass', 'name', 'geometry']]\n",
    "# Keep only the roads whose \"fclass\" is in the list\n",
    "GHA_OSM_roads = GHA_OSM_roads[\n",
    "    GHA_OSM_roads.fclass.isin([\n",
    "        'motorway',\n",
    "        'motorway_link',\n",
    "        'trunk',\n",
    "        'trunk_link',\n",
    "        'primary', \n",
    "        'primary_link',\n",
    "        'secondary', \n",
    "        'secondary_link', \n",
    "        'tertiary',\n",
    "        'tertiary_link'\n",
    "    ])\n",
    "]\n",
    "# Reset the index numbering\n",
    "GHA_OSM_roads = GHA_OSM_roads.reset_index(drop=True).reset_index()\n",
    "# Rename some columns\n",
    "GHA_OSM_roads = GHA_OSM_roads.rename(\n",
    "    columns={\n",
    "        'index': 'id',\n",
    "        'fclass': 'road_type',\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the length of each road segment in meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geod = Geod(ellps='WGS84')\n",
    "GHA_OSM_roads['length_m'] = GHA_OSM_roads.geometry.apply(geod.geometry_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GHA_OSM_roads.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9) Save the pre-processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GHA_OSM_roads.to_file(\n",
    "    os.path.join(data_folder, 'GHA_OSM_roads.gpkg'),\n",
    "    layer='OSM-roads', \n",
    "    driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 2: Extract and polygonise hazard data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1) Download a few tif files from Aqueduct\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all downloaded tif files in a new folder titled `flood_layer` under your data_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2) Run the code below to polygonise the tif files\n",
    "\n",
    "This converts the flood maps from *tiff files (raster data)* into *shape files (vector data)*. It will take a little time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = \"-3.262509\"\n",
    "ymin = \"4.737128\"\n",
    "xmax = \"1.187968\"\n",
    "ymax = \"11.162937\"\n",
    "\n",
    "for root, dirs, files in os.walk(data_folder, 'flood_layer'): \n",
    "    print(\"Looking in\", root) \n",
    "    for file in sorted(files): \n",
    "        if file.endswith(\".tif\") and not file.endswith(\"m.tif\"): \n",
    "            print(\"Found tif file\", file)\n",
    "            stem = file[:-4]\n",
    "            input_file = os.path.join(root, file) \n",
    "            \n",
    "            # Clip file to bounds\n",
    "            clip_file = os.path.join(root, f\"{stem}_clipm.tif\")\n",
    "            try:\n",
    "                os.remove(clip_file)\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "            p = subprocess.run([\n",
    "                \"gdalwarp\", \"-te\", xmin, ymin, xmax, ymax, input_file, clip_file],\n",
    "                capture_output=True)\n",
    "            print(p.stdout.decode('utf8'))\n",
    "            print(p.stderr.decode('utf8'))\n",
    "            print(clip_file)\n",
    "            \n",
    "            for min_depth in (\"1.0\", \"2.0\"):\n",
    "                # Create binary raster at threshold\n",
    "                threshold_file = os.path.join(root, f\"{stem}_{min_depth}m999.0m.tif\")\n",
    "                p = subprocess.run([\n",
    "                    \"gdal_calc.py\",\n",
    "                    \"-A\", clip_file,\n",
    "                    f\"--outfile={threshold_file}\",\n",
    "                    f\"--calc=A>={min_depth}\",\n",
    "                    \"--type=Byte\",\n",
    "                    \"--NoDataValue=0\",\n",
    "                    \"--co=SPARSE_OK=YES\",\n",
    "                    \"--co=NBITS=1\",\n",
    "                    \"--quiet\",\n",
    "                    \"--co=COMPRESS=LZW\"],\n",
    "                    capture_output=True)\n",
    "                print(p.stdout.decode('utf8'))\n",
    "                print(p.stderr.decode('utf8'))\n",
    "                print(threshold_file)\n",
    "                \n",
    "                # Create vector outline of raster areas\n",
    "                polygons_file = os.path.join(root, f\"{stem}_{min_depth}m999.0m.gpkg\") \n",
    "                try:\n",
    "                    os.remove(polygons_file)\n",
    "                except FileNotFoundError:\n",
    "                    pass\n",
    "                p = subprocess.run([\n",
    "                    \"gdal_polygonize.py\", threshold_file,'-q','-f', 'GPKG', polygons_file],\n",
    "                    capture_output=True)\n",
    "                print(p.stdout.decode('utf8'))\n",
    "                print(p.stderr.decode('utf8'))  \n",
    "                print(polygons_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 3: Intersect hazard "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now intersect the hazard and the roads, starting with one hazard initially so we save time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1) Specify your input and output path as well as the name of the intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_path = os.path.join(\n",
    "    data_folder, \n",
    "    'flood_layer', \n",
    "    'inunriver_historical_000000000WATCH_1980_rp00010_1.0m999.0m.gpkg')\n",
    "\n",
    "output_path = os.path.join(\n",
    "    data_folder, \n",
    "    'results', \n",
    "    'inunriver_historical_000000000WATCH_1980_rp00010_1.0m999.0m_exposure.gpkg')\n",
    "\n",
    "flood_gpd = gpd.read_file(flood_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2) Run the intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_intersections = gpd.overlay(GHA_OSM_roads, flood_gpd, how='intersection')\n",
    "# flood_intersections = gpd.clip(GHA_OSM_roads, flood_gpd, keep_geom_type=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the exposed length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geod = Geod(ellps='WGS84')\n",
    "flood_intersections['flood_length_m'] = flood_intersections.geometry.apply(geod.geometry_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GHA_OSM_roads[GHA_OSM_roads.osm_id == \"863568484\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_intersections.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the proportion of roads in our dataset which are exposed to >=1m flood depths in this scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposed_length = flood_intersections.flood_length_m.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_roads_in_dataset_length = GHA_OSM_roads.length_m.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = exposed_length / all_roads_in_dataset_length\n",
    "proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{proportion:.0%} of roads in this dataset are exposed to flood depths of >= 1m in a historical 1-in-10 year flood\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to file (with spatial data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_intersections.to_file(output_path, driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_intersections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to CSV (without spatial data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_intersections.drop(columns='geometry').to_csv(output_path.replace(\".gpkg\", \".csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
