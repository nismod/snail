{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "spoken-texture",
   "metadata": {},
   "source": [
    "# Modelling infrastructure exposure and risk\n",
    "\n",
    "This notebook forms the basis of \"Hands-On 6\" in the CCG course.\n",
    "\n",
    "It uses the road network and flood dataset extracted in the previous tutorial.\n",
    "\n",
    "1. Exposure - overlay sample flood extent with the network and estimate flood depth of exposure\n",
    "2. Vulnerability - assume depth-damage curve (fragility curve) for the road and\n",
    "   - show how the exposure is translated to damage\n",
    "   - create a table with probability, flood depth, length exposed, fragility, cost/km, direct damage\n",
    "4. Risk - show a risk calculation on the table and generate the result\n",
    "5. Future risk - repeat with climate projections and compare with baseline\n",
    "\n",
    "By the end of this tutorial you should be able to:\n",
    "* Assess direct damage and indirect disruptions to infrastructure assets\n",
    "* Apply the risk calculation to understand how to generate loss-probability curves\n",
    "* Show how different flood hazards introduce uncertainty in risk estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports from Python standard library\n",
    "import os\n",
    "\n",
    "# see https://docs.python.org/3/library/warnings.html\n",
    "import warnings\n",
    "\n",
    "# see https://docs.python.org/3/library/glob.html\n",
    "from glob import glob\n",
    "\n",
    "# Imports from other Python packages\n",
    "import geopandas as gpd\n",
    "\n",
    "# numpy is used by pandas and geopandas to store data in efficient arrays\n",
    "# we use it in this notebook to help with trapezoidal integration\n",
    "# see https://numpy.org/\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# seaborn helps produce more complex plots\n",
    "# see https://seaborn.pydata.org/\n",
    "import seaborn as sns\n",
    "from pyproj import Geod\n",
    "\n",
    "# tqdm lets us show progress bars (and تقدّم means \"progress\" in Arabic)\n",
    "# see https://tqdm.github.io/\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-reputation",
   "metadata": {},
   "source": [
    "Change this to point to your data folder as in the previous tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-knife",
   "metadata": {},
   "source": [
    "## 1. Exposure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-passion",
   "metadata": {},
   "source": [
    "List all the hazard files in the `flood_layer` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazard_files = sorted(glob(os.path.join(data_folder, \"flood_layer/*.gpkg\")))\n",
    "hazard_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_without_warnings(path, **kwd):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        data = gpd.read_file(path, **kwd)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-consciousness",
   "metadata": {},
   "source": [
    "Read in roads again, then do intersections against all hazard scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "roads = read_file_without_warnings(\n",
    "    os.path.join(data_folder, \"GHA_OSM_roads.gpkg\"), layer=\"edges\"\n",
    ")\n",
    "roads.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hazard_file in tqdm(hazard_files):\n",
    "    # read file\n",
    "    flood = read_file_without_warnings(hazard_file).rename(\n",
    "        columns={\"DN\": \"depth_m\"}\n",
    "    )\n",
    "    flood = flood[flood.depth_m > 0]\n",
    "\n",
    "    # run intersection\n",
    "    intersections = gpd.overlay(roads, flood, how=\"intersection\")\n",
    "    # calculate intersection lengths\n",
    "    geod = Geod(ellps=\"WGS84\")\n",
    "    intersections[\"flood_length_m\"] = intersections.geometry.apply(\n",
    "        geod.geometry_length\n",
    "    )\n",
    "    # save file\n",
    "    output_file = os.path.join(\n",
    "        data_folder,\n",
    "        \"results\",\n",
    "        os.path.basename(hazard_file).replace(\".gpkg\", \"_exposure.gpkg\"),\n",
    "    )\n",
    "    if len(intersections):\n",
    "        intersections.to_file(output_file, driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-chile",
   "metadata": {},
   "source": [
    "List all the results just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_files = sorted(\n",
    "    glob(os.path.join(data_folder, \"results/inunriver*.gpkg\"))\n",
    ")\n",
    "intersection_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-glory",
   "metadata": {},
   "source": [
    "Read and combine all the exposed lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_intersections = []\n",
    "\n",
    "for intersection_file in tqdm(intersection_files):\n",
    "    # split up the filename to pull out metadata\n",
    "    hazard, rcp, gcm, epoch, rp, _ = os.path.basename(intersection_file).split(\n",
    "        \"_\"\n",
    "    )\n",
    "    gcm = gcm.replace(\"0\", \"\")\n",
    "    rp = int(rp.replace(\"rp\", \"\"))\n",
    "    epoch = int(epoch)\n",
    "\n",
    "    # read file\n",
    "    intersections = read_file_without_warnings(intersection_file)\n",
    "    # drop road length and geometry fields\n",
    "    intersections.drop(columns=\"length_m\", inplace=True)\n",
    "    # add metadata about the hazard and scenario\n",
    "    intersections[\"hazard\"] = hazard\n",
    "    intersections[\"rcp\"] = rcp\n",
    "    intersections[\"gcm\"] = gcm\n",
    "    intersections[\"epoch\"] = epoch\n",
    "    intersections[\"rp\"] = rp\n",
    "\n",
    "    all_intersections.append(intersections)\n",
    "\n",
    "# group all together\n",
    "all_intersections = pd.concat(all_intersections)\n",
    "all_intersections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-output",
   "metadata": {},
   "source": [
    "Summarise total length of roads exposed to depth 2m or greater flooding, under different return periods and climate scenarios:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    all_intersections[all_intersections.depth_m >= 2.0]\n",
    "    .groupby([\"hazard\", \"rcp\", \"gcm\", \"epoch\", \"rp\"])\n",
    "    .sum()\n",
    "    .drop(columns=[\"depth_m\"])\n",
    ")\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-berlin",
   "metadata": {},
   "source": [
    "Plot exposure against return period, with separate plot areas for each Representative Concentration Pathway (RCP), and different colours for the different Global Climate Models (GCM): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(\n",
    "    \"rp\",\n",
    "    \"flood_length_m\",\n",
    "    data=summary.reset_index(),\n",
    "    hue=\"gcm\",\n",
    "    col=\"rcp\",\n",
    "    fit_reg=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-technical",
   "metadata": {},
   "source": [
    "## 2. Vulnerability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-edinburgh",
   "metadata": {},
   "source": [
    "Set up fragility curve assumptions, where probability of damage (`pfail`) depends on whether a road is paved and the depth of flood it is exposed to. \n",
    "\n",
    "These assumptions are derived from Koks, E.E., Rozenberg, J., Zorn, C. et al. A global multi-hazard risk analysis of road and railway infrastructure assets. Nat Commun 10, 2677 (2019). https://doi.org/10.1038/s41467-019-10442-3, Figure S3, extrapolated to 2m and 3m depths. \n",
    "\n",
    "The analysis is likely to be highly sensitive to these assumptions, and this approach is strongly limited by the availability and quality of fragility data, as well as the assumption that fragility can be related to flood depth alone - flood water velocity would be an important factor in a more detailed vulnerability assessment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "fragility = pd.DataFrame(\n",
    "    {\n",
    "        \"paved\": [True, True, True, False, False, False],\n",
    "        \"depth_m\": [\"1\", \"2\", \">=3\", \"1\", \"2\", \">=3\"],\n",
    "        \"pfail\": [0.1, 0.3, 0.5, 0.9, 1.0, 1.0],\n",
    "    }\n",
    ")\n",
    "fragility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-vegetation",
   "metadata": {},
   "source": [
    "Set up cost assumptions. \n",
    "\n",
    "These are taken from Koks et al (2019) again, Table S8, construction costs to be assumed as an estimate of full rehabilitation after flood damage. \n",
    "\n",
    "Again the analysis is likely to be highly sensitive to these assumptions, which should be replaced by better estimates if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = pd.DataFrame(\n",
    "    {\n",
    "        \"kind\": [\"paved_four_lane\", \"paved_two_lane\", \"unpaved\"],\n",
    "        \"cost_usd_per_km\": [3_800_000, 932_740, 22_780],\n",
    "    }\n",
    ")\n",
    "costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-communication",
   "metadata": {},
   "source": [
    "Set up assumptions about which roads are paved or unpaved, and number of lanes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(all_intersections.road_type.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-kernel",
   "metadata": {},
   "source": [
    "Assume all `tertiary` roads are unpaved, all others are paved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_intersections[\"paved\"] = ~(all_intersections.road_type == \"tertiary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kind(road_type):\n",
    "    if road_type in (\"trunk\", \"trunk_link\", \"motorway\"):\n",
    "        return \"paved_four_lane\"\n",
    "    elif road_type in (\"primary\", \"primary_link\", \"secondary\"):\n",
    "        return \"paved_two_lane\"\n",
    "    else:\n",
    "        return \"unpaved\"\n",
    "\n",
    "\n",
    "all_intersections[\"kind\"] = all_intersections.road_type.apply(kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_intersections = all_intersections.merge(costs, on=\"kind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-friend",
   "metadata": {},
   "source": [
    "Discard all information on flood depths greater than 3m in order to use the fragility curve to estimate `pfail` for each exposed section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_intersections_coarse_depth = all_intersections.copy()\n",
    "all_intersections_coarse_depth.depth_m = (\n",
    "    all_intersections_coarse_depth.depth_m.apply(\n",
    "        lambda d: str(d) if d < 3 else \">=3\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_intersections_coarse_depth = all_intersections_coarse_depth.merge(\n",
    "    fragility, on=[\"depth_m\", \"paved\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-offense",
   "metadata": {},
   "source": [
    "Finally estimate cost of rehabilitation for each exposed section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_intersections_coarse_depth[\"damage_usd\"] = (\n",
    "    all_intersections_coarse_depth.flood_length_m\n",
    "    * all_intersections_coarse_depth.cost_usd_per_km\n",
    "    / 1000\n",
    ")\n",
    "all_intersections_coarse_depth.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_intersections_coarse_depth.to_file(\n",
    "    os.path.join(data_folder, \"results/flood_exposure.gpkg\"), driver=\"GPKG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_intersections_coarse_depth.drop(columns=\"geometry\").to_csv(\n",
    "    os.path.join(data_folder, \"results/flood_exposure.csv\"), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    all_intersections_coarse_depth.groupby(\n",
    "        [\"hazard\", \"rcp\", \"gcm\", \"epoch\", \"rp\"]\n",
    "    )\n",
    "    .sum()\n",
    "    .drop(columns=[\"paved\", \"cost_usd_per_km\", \"pfail\"])\n",
    ")\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-interval",
   "metadata": {},
   "source": [
    "## 3. Risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-neutral",
   "metadata": {},
   "source": [
    "Calculate expected annual damages for each road under historical hazard.\n",
    "\n",
    "Start by selecting only historical intersections, and keeping only the road ID, return period, probability of damage, and cost of rehabilitation if damaged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical = all_intersections_coarse_depth[\n",
    "    all_intersections_coarse_depth.rcp == \"historical\"\n",
    "][[\"id\", \"rp\", \"pfail\", \"damage_usd\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-pierre",
   "metadata": {},
   "source": [
    "Calculated the expected damage for each length exposed (under a given return period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-soldier",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical[\"expected_damage_usd\"] = historical.pfail * historical.damage_usd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-accident",
   "metadata": {},
   "source": [
    "Sum up the expected damage for each road, per return period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical = (\n",
    "    historical.groupby([\"id\", \"rp\"])\n",
    "    .sum()\n",
    "    .drop(columns=[\"pfail\", \"damage_usd\"])\n",
    "    .reset_index()\n",
    ")\n",
    "historical.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-martial",
   "metadata": {},
   "source": [
    "Pivot the table to create columns for each return period - now there is one row per road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical = historical.pivot(index=\"id\", columns=\"rp\").replace(\n",
    "    float(\"NaN\"), 0\n",
    ")\n",
    "historical.columns = [f\"rp{rp}\" for _, rp in historical.columns]\n",
    "historical.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-victor",
   "metadata": {},
   "source": [
    "Calculate expected annual damages, integrating under the expected damage curve over return periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_annual_damages(row):\n",
    "    return np.trapz([row.rp1000, row.rp100, row.rp10], x=[0.001, 0.01, 0.1])\n",
    "\n",
    "\n",
    "historical[\"ead_usd\"] = historical.apply(expected_annual_damages, axis=1)\n",
    "historical.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-wings",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical.to_csv(\n",
    "    os.path.join(data_folder, \"results/flood_risk_historical.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-arlington",
   "metadata": {},
   "source": [
    "## 4. Future risk\n",
    "\n",
    "Calculate expected annual damages under each future scenario (for each global climate model and representative concentration pathway).\n",
    "\n",
    "This follows the same method as for historical flooding above, with the added variables of climate model and rcp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "future = all_intersections_coarse_depth[\n",
    "    [\"id\", \"rp\", \"rcp\", \"gcm\", \"pfail\", \"damage_usd\"]\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-warehouse",
   "metadata": {},
   "source": [
    "Calculated the expected damage for each length exposed (under a given return period, gcm and rcp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "future[\"expected_damage_usd\"] = future.pfail * future.damage_usd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-origin",
   "metadata": {},
   "source": [
    "Sum up the expected damage for each road, per return period, gcm and rcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "future = (\n",
    "    future.groupby([\"id\", \"rp\", \"rcp\", \"gcm\"])\n",
    "    .sum()\n",
    "    .drop(columns=[\"pfail\", \"damage_usd\"])\n",
    "    .reset_index()\n",
    ")\n",
    "future.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-frame",
   "metadata": {},
   "source": [
    "Pivot the table to create columns for each return period - now there is one row per road, gcm and rcp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "future = future.pivot(index=[\"id\", \"rcp\", \"gcm\"], columns=\"rp\").replace(\n",
    "    float(\"NaN\"), 0\n",
    ")\n",
    "future.columns = [f\"rp{rp}\" for _, rp in future.columns]\n",
    "future.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-china",
   "metadata": {},
   "source": [
    "Calculate expected annual damages, integrating under the expected damage curve over return periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-powell",
   "metadata": {},
   "outputs": [],
   "source": [
    "future[\"ead_usd\"] = future.apply(expected_annual_damages, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "future.to_csv(os.path.join(data_folder, \"results/flood_risk.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-agenda",
   "metadata": {},
   "source": [
    "Pick out an individual road by id, to spot check uncertainty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "future.loc[\"roade_10028\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-hungarian",
   "metadata": {},
   "source": [
    "Summarise total expected annual (direct) damages, showing variation between climate models and representative concentration pathways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    future.reset_index()\n",
    "    .drop(columns=[\"id\", \"rp10\", \"rp100\", \"rp1000\"])\n",
    "    .groupby([\"rcp\", \"gcm\"])\n",
    "    .sum()\n",
    ")\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(\n",
    "    \"rcp\", \"ead_usd\", data=summary.reset_index(), hue=\"gcm\", fit_reg=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
