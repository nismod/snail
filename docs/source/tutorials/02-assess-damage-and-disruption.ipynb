{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "spoken-texture",
   "metadata": {},
   "source": [
    "## Modelling infrastructure exposure and risk\n",
    "\n",
    "\n",
    "This notebook forms the basis of \"Hands-On 6\" in the CCG course.\n",
    "\n",
    "It uses the road network and flood dataset extracted in the previous tutorial.\n",
    "\n",
    "1. Exposure - overlay sample flood extent with the network and estimate flood depth of exposure\n",
    "2. Vulnerability - assume depth-damage curve (fragility curve) for the road and\n",
    "   - show how the exposure is translated to damage\n",
    "   - create a table with probability, flood depth, length exposed, fragility, cost/km, direct damage\n",
    "4. Risk - show a risk calculation on the table and generate the result\n",
    "5. Future risk - repeat with climate projections and compare with baseline\n",
    "\n",
    "By the end of this tutorial you should be able to:\n",
    "* Assess direct damage and indirect disruptions to infrastructure assets\n",
    "* Apply the risk calculation to understand how to generate loss-probability curves\n",
    "* Show how different flood hazards introduce uncertainty in risk estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports from Python standard library\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# see https://docs.python.org/3/library/glob.html\n",
    "from glob import glob\n",
    "\n",
    "# Imports from other Python packages\n",
    "import geopandas as gpd\n",
    "\n",
    "# numpy is used by pandas and geopandas to store data in efficient arrays\n",
    "# we use it in this notebook to help with trapezoidal integration\n",
    "# see https://numpy.org/\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# seaborn helps produce more complex plots\n",
    "# see https://seaborn.pydata.org/\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.integrate import simpson\n",
    "\n",
    "import snail.damages\n",
    "import snail.intersection\n",
    "import snail.io\n",
    "\n",
    "from pyproj import Geod\n",
    "\n",
    "# tqdm lets us show progress bars (and تقدّم means \"progress\" in Arabic)\n",
    "# see https://tqdm.github.io/\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "characteristic-reputation",
   "metadata": {},
   "source": [
    "Change this to point to your data folder as in the previous tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = (\n",
    "    Path(os.getcwd()).resolve().parents[3]\n",
    ")  # get parent directory of snail package\n",
    "data_folder = os.path.join(dir, \"ghana_tutorial\")\n",
    "# data_folder = Path(\"YOUR_PATH/ghana_tutorial\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "hired-knife",
   "metadata": {},
   "source": [
    "### 1. Exposure\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "defensive-passion",
   "metadata": {},
   "source": [
    "List all the hazard files in the `flood_layer` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazard_paths = sorted(\n",
    "    glob(str(data_folder + \"/flood_layer/gha/wri_aqueduct_version_2/wri*.tif\"))\n",
    ")\n",
    "hazard_files = pd.DataFrame({\"path\": hazard_paths})\n",
    "hazard_files[\"key\"] = [Path(path).stem for path in hazard_paths]\n",
    "hazard_files, grids = snail.io.extend_rasters_metadata(hazard_files)\n",
    "\n",
    "hazard_files.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe43d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(grids) == 1\n",
    "grid = grids[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "described-consciousness",
   "metadata": {},
   "source": [
    "Read in roads again, then do intersections against all hazard scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_file = data_folder + \"/GHA_OSM_roads.gpkg\"\n",
    "roads = gpd.read_file(roads_file, layer=\"edges\")\n",
    "roads.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split roads along hazard data grid\n",
    "\n",
    "# TODO top-level \"overlay_rasters\"\n",
    "# TODO for vector in vectors / for raster in rasters \"overlay_raster\"\n",
    "\n",
    "\n",
    "# push into split_linestrings, flag to disable\n",
    "prepared = snail.intersection.prepare_linestrings(roads)\n",
    "\n",
    "flood_intersections = snail.intersection.split_linestrings(prepared, grid)\n",
    "\n",
    "# push into split_linestrings\n",
    "flood_intersections = snail.intersection.apply_indices(\n",
    "    flood_intersections, grid, index_i=\"i_0\", index_j=\"j_0\"\n",
    ")\n",
    "\n",
    "flood_intersections = snail.io.associate_raster_files(\n",
    "    flood_intersections, hazard_files\n",
    ")\n",
    "\n",
    "# calculate the length of each stretch of road\n",
    "# don't include in snail wrapper top-level function\n",
    "geod = Geod(ellps=\"WGS84\")\n",
    "flood_intersections[\"length_m\"] = flood_intersections.geometry.apply(\n",
    "    geod.geometry_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2207fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "output_file = os.path.join(\n",
    "    data_folder,\n",
    "    \"results\",\n",
    "    str(Path(roads_file).name).replace(\n",
    "        \".gpkg\", \"_edges___exposure.geoparquet\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "flood_intersections.to_parquet(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_intersections.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7fbaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cols = [col for col in flood_intersections.columns if \"wri\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f345f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find any max depth and filter > 0\n",
    "all_intersections = flood_intersections[\n",
    "    flood_intersections[data_cols].max(axis=1) > 0\n",
    "]\n",
    "# subset columns\n",
    "all_intersections = all_intersections.drop(\n",
    "    columns=[\"osm_id\", \"name\", \"from_id\", \"to_id\", \"geometry\", \"i_0\", \"j_0\"]\n",
    ")\n",
    "# melt and check again for depth\n",
    "all_intersections = all_intersections.melt(\n",
    "    id_vars=[\"id\", \"split\", \"road_type\", \"length_m\"],\n",
    "    value_vars=data_cols,\n",
    "    var_name=\"key\",\n",
    "    value_name=\"depth_m\",\n",
    ").query(\"depth_m > 0\")\n",
    "\n",
    "all_intersections.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320791b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "river = all_intersections[all_intersections.key.str.contains(\"inunriver\")]\n",
    "coast = all_intersections[all_intersections.key.str.contains(\"inuncoast\")]\n",
    "\n",
    "coast_keys = coast.key.str.extract(\n",
    "    r\"wri_aqueduct-version_2-(?P<hazard>\\w+)_(?P<rcp>[^_]+)_(?P<sub>[^_]+)_(?P<epoch>[^_]+)_rp(?P<rp>[^-]+)-gha\"\n",
    ")\n",
    "coast = pd.concat([coast, coast_keys], axis=1)\n",
    "river_keys = river.key.str.extract(\n",
    "    r\"wri_aqueduct-version_2-(?P<hazard>\\w+)_(?P<rcp>[^_]+)_(?P<gcm>[^_]+)_(?P<epoch>[^_]+)_rp(?P<rp>[^-]+)-gha\"\n",
    ")\n",
    "river = pd.concat([river, river_keys], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6430bb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coast.rp = coast.rp.apply(lambda rp: float(rp.replace(\"_\", \".\").lstrip(\"0\")))\n",
    "coast.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849afbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# river.rp = river.rp.apply(lambda rp: float(rp.replace(\"_\", \".\").lstrip(\"0\")))\n",
    "river.gcm = river.gcm.str.replace(\"0\", \"\")\n",
    "river.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "removable-output",
   "metadata": {},
   "source": [
    "Summarise total length of roads exposed to depth 2m or greater river flooding, under different return periods and climate scenarios:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    river[river.depth_m >= 2.0]\n",
    "    .drop(columns=[\"id\", \"split\", \"road_type\", \"key\"])\n",
    "    .groupby([\"hazard\", \"rcp\", \"gcm\", \"epoch\", \"rp\"])\n",
    "    .sum()\n",
    "    .drop(columns=[\"depth_m\"])\n",
    ")\n",
    "\n",
    "summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "southeast-berlin",
   "metadata": {},
   "source": [
    "Plot exposure against return period, with separate plot areas for each Representative Concentration Pathway (RCP), and different colours for the different Global Climate Models (GCM): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f3962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = summary.reset_index()\n",
    "plot_data = plot_data[plot_data.epoch.isin([\"1980\", \"2080\"])]\n",
    "plot_data.rp = plot_data.rp.apply(lambda rp: int(rp.lstrip(\"0\")))\n",
    "plot_data[\"probability\"] = 1 / plot_data.rp\n",
    "plot_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=plot_data,\n",
    "    x=\"rp\",\n",
    "    y=\"length_m\",\n",
    "    hue=\"gcm\",\n",
    "    col=\"rcp\",\n",
    "    kind=\"line\",\n",
    "    marker=\"o\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "global-technical",
   "metadata": {},
   "source": [
    "### 2. Vulnerability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "prostate-edinburgh",
   "metadata": {},
   "source": [
    "Set up fragility curve assumptions, where probability of damage (`pfail`) depends on whether a road is paved and the depth of flood it is exposed to. \n",
    "\n",
    "These assumptions are derived from Koks, E.E., Rozenberg, J., Zorn, C. et al. A global multi-hazard risk analysis of road and railway infrastructure assets. Nat Commun 10, 2677 (2019). https://doi.org/10.1038/s41467-019-10442-3, Figure S3, extrapolated to 2m and 3m depths. \n",
    "\n",
    "The analysis is likely to be highly sensitive to these assumptions, and this approach is strongly limited by the availability and quality of fragility data, as well as the assumption that fragility can be related to flood depth alone - flood water velocity would be an important factor in a more detailed vulnerability assessment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "paved = snail.damages.PiecewiseLinearDamageCurve(\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"intensity\": [0.0, 0.999999999, 1, 2, 3],\n",
    "            \"damage\": [0.0, 0.0, 0.1, 0.3, 0.5],\n",
    "        }\n",
    "    )\n",
    ")\n",
    "unpaved = snail.damages.PiecewiseLinearDamageCurve(\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"intensity\": [0.0, 0.999999999, 1, 2, 3],\n",
    "            \"damage\": [0.0, 0.0, 0.9, 1.0, 1.0],\n",
    "        }\n",
    "    )\n",
    ")\n",
    "paved, unpaved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e54e59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "paved.plot(), unpaved.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "optical-vegetation",
   "metadata": {},
   "source": [
    "Set up cost assumptions. \n",
    "\n",
    "These are taken from Koks et al (2019) again, Table S8, construction costs to be assumed as an estimate of full rehabilitation after flood damage. \n",
    "\n",
    "Again the analysis is likely to be highly sensitive to these assumptions, which should be replaced by better estimates if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = pd.DataFrame(\n",
    "    {\n",
    "        \"kind\": [\"paved_four_lane\", \"paved_two_lane\", \"unpaved\"],\n",
    "        \"cost_usd_per_km\": [3_800_000, 932_740, 22_780],\n",
    "    }\n",
    ")\n",
    "costs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "applied-communication",
   "metadata": {},
   "source": [
    "Set up assumptions about which roads are paved or unpaved, and number of lanes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(river.road_type.unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "sonic-kernel",
   "metadata": {},
   "source": [
    "Assume all `tertiary` roads are unpaved, all others are paved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "river[\"paved\"] = ~(river.road_type == \"tertiary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kind(road_type):\n",
    "    if road_type in (\"trunk\", \"trunk_link\", \"motorway\"):\n",
    "        return \"paved_four_lane\"\n",
    "    elif road_type in (\"primary\", \"primary_link\", \"secondary\"):\n",
    "        return \"paved_two_lane\"\n",
    "    else:\n",
    "        return \"unpaved\"\n",
    "\n",
    "\n",
    "river[\"kind\"] = river.road_type.apply(kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "river = river.merge(costs, on=\"kind\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "turkish-friend",
   "metadata": {},
   "source": [
    "Use the damage curve to estimate `proportion_damaged` for each exposed section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "river.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "paved_depths = river.loc[river.paved, \"depth_m\"]\n",
    "paved_damage = paved.damage_fraction(paved_depths)\n",
    "river.loc[river.paved, \"proportion_damaged\"] = paved_damage\n",
    "\n",
    "unpaved_depths = river.loc[~river.paved, \"depth_m\"]\n",
    "unpaved_damage = paved.damage_fraction(unpaved_depths)\n",
    "river.loc[~river.paved, \"proportion_damaged\"] = unpaved_damage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "checked-offense",
   "metadata": {},
   "source": [
    "Finally estimate cost of rehabilitation for each exposed section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "river[\"damage_usd\"] = river.length_m * river.cost_usd_per_km * 1e-3\n",
    "river.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "river.to_csv(\n",
    "    os.path.join(data_folder, \"results/inunriver_damages_rp.csv\"), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    river.drop(\n",
    "        columns=[\n",
    "            \"id\",\n",
    "            \"split\",\n",
    "            \"length_m\",\n",
    "            \"key\",\n",
    "            \"depth_m\",\n",
    "            \"paved\",\n",
    "            \"kind\",\n",
    "            \"cost_usd_per_km\",\n",
    "            \"proportion_damaged\",\n",
    "        ]\n",
    "    )\n",
    "    .groupby([\"road_type\", \"hazard\", \"rcp\", \"gcm\", \"epoch\", \"rp\"])\n",
    "    .sum()\n",
    ")\n",
    "summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "designed-interval",
   "metadata": {},
   "source": [
    "### 3. Risk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "reverse-neutral",
   "metadata": {},
   "source": [
    "Calculate expected annual damages for each road under historical hazard.\n",
    "\n",
    "Start by selecting only historical intersections, and keeping only the road ID, return period, and cost of rehabilitation if damaged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical = river[river.rcp == \"historical\"][[\"id\", \"rp\", \"damage_usd\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "juvenile-accident",
   "metadata": {},
   "source": [
    "Sum up the expected damage for each road, per return period, then pivot the table to create columns for each return period - now there is one row per road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical = historical.groupby([\"id\", \"rp\"]).sum().reset_index()\n",
    "historical = historical.pivot(index=\"id\", columns=\"rp\").replace(\n",
    "    float(\"NaN\"), 0\n",
    ")\n",
    "historical.columns = [f\"rp{int(rp)}\" for _, rp in historical.columns]\n",
    "historical.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "mexican-victor",
   "metadata": {},
   "source": [
    "Calculate expected annual damages, integrating under the expected damage curve over return periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ead(df):\n",
    "    rp_cols = sorted(\n",
    "        list(df.columns), key=lambda col: 1 / int(col.replace(\"rp\", \"\"))\n",
    "    )\n",
    "    rps = np.array([int(col.replace(\"rp\", \"\")) for col in rp_cols])\n",
    "    probabilities = 1 / rps\n",
    "    rp_damages = df[rp_cols]\n",
    "    return simpson(rp_damages, x=probabilities, axis=1)\n",
    "\n",
    "\n",
    "historical[\"ead_usd\"] = calculate_ead(historical)\n",
    "historical.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-wings",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical.to_csv(\n",
    "    os.path.join(data_folder, \"results/inunriver_damages_ead__historical.csv\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "thick-arlington",
   "metadata": {},
   "source": [
    "### 4. Future risk\n",
    "\n",
    "Calculate expected annual damages under each future scenario (for each global climate model and representative concentration pathway).\n",
    "\n",
    "This follows the same method as for historical flooding above, with the added variables of climate model and rcp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "future = river[[\"id\", \"rp\", \"rcp\", \"gcm\", \"epoch\", \"damage_usd\"]].copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "endless-origin",
   "metadata": {},
   "source": [
    "Sum up the expected damage for each road, per return period, gcm and rcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "future = (\n",
    "    future.groupby([\"id\", \"rp\", \"rcp\", \"gcm\", \"epoch\"]).sum().reset_index()\n",
    ")\n",
    "future.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "natural-frame",
   "metadata": {},
   "source": [
    "Pivot the table to create columns for each return period - now there is one row per road, gcm and rcp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "future = future.pivot(\n",
    "    index=[\"id\", \"rcp\", \"gcm\", \"epoch\"], columns=\"rp\"\n",
    ").replace(float(\"NaN\"), 0)\n",
    "future.columns = [f\"rp{int(rp)}\" for _, rp in future.columns]\n",
    "future.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ceramic-china",
   "metadata": {},
   "source": [
    "Calculate expected annual damages, integrating under the expected damage curve over return periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-powell",
   "metadata": {},
   "outputs": [],
   "source": [
    "future[\"ead_usd\"] = calculate_ead(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "future.to_csv(os.path.join(data_folder, \"results/inunriver_damages_ead.csv\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "genuine-agenda",
   "metadata": {},
   "source": [
    "Pick out an individual road by id, to spot check uncertainty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42794000",
   "metadata": {},
   "outputs": [],
   "source": [
    "future.reset_index().id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "# future.loc[\"roade_1002\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bridal-hungarian",
   "metadata": {},
   "source": [
    "Summarise total expected annual (direct) damages, showing variation between climate models and representative concentration pathways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    future.reset_index()[[\"rcp\", \"gcm\", \"epoch\", \"ead_usd\"]]\n",
    "    .groupby([\"rcp\", \"gcm\", \"epoch\"])\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "summary.epoch = summary.epoch.astype(int)\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(\n",
    "    data=summary,\n",
    "    col=\"rcp\",\n",
    "    x=\"epoch\",\n",
    "    y=\"ead_usd\",\n",
    "    hue=\"gcm\",  # fit_reg=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
